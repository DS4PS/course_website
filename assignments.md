---
layout: default
---

<style>
th {
    padding: 3px 10px 3px 10px;
    text-align: left;
}
td {
    padding: 3px 10px 3px 10px;
    text-align: left;
}
a {
    text-transform: uppercase;
    font-weight: bold;
}
</style>


<div class = "uk-container uk-container-small">
 
<br><br>

## Topics

{:.no_toc}
* TOC
{:toc}


--------
<br>



# Review Sessions: 

Attend in-person sessions at the following times and locations:

**Wednesday, 6pm-7pm**
* Meet in **UCENT 580A** all semester 
* We will not meet Oct 31st or Nov 21st 
* *If after 6pm, take elevator to 4th floor, turn right, take first stairs to 5th floor*

**Thursday, 1pm-2pm** 
* **Most weeks** we will meet in **UCENT 480A** 
* Thursday, Nov 15th we will meet in **UCENT 705** 
* We will not meet Nov 1st or Nov 22nd 


<br>

-----------------
<br>




# Grades

Your grade is comprised of the following:
 
* 60% - Weekly labs  
* 20% - Final project 
* 20% - Discussion boards 

Labs will give you practice with the key concepts and functions of the week. They are graded pass-fail and you get to drop one lab (chances are you will have one rough week this semester). To pass you need to get at least half of the questions correct and demonstrate that you understand the material. 

This grading system is designed as a way for you to focus on the big picture each week and not worry if a specific function or model is not working properly. Computer languages can be unforgiving in the sense that one minor error can prevent the program from running. 

Learning a programming language is a lot like learning a natural language in that it is easy to become conversant enough to find your way around a city and order some food at a restaurant, but much harder to become fluent. The goal is for you to become conversant in R by the end of the semester so that you can begin using tutorials and discussion forums to further your journey.

The YellowDig discussion boards are used to introduce you to the data science ecosystem. We cannot cover a lot of topics in-depth, so the discussions are a chance to explore some resources or reflect on a specific article. You need to earn at least 100 points through the semester by posting topics and interacting with peers. The points are earned as follows: 

* 5 points for a new pin with at least 50 words.
* 2 points for a comment made to another pin.
* 1 point if you receive a comment on your pin. 
* 1 point for liking another pin.
* 5 points if you earn an instructor badge for an informative post.
* max of 20 points can be earned each week. 
* 100 points or more earns you an A for discussions. 

The final project will require you to practice skills from the semester by building a basic dashboard.


<br>

-----------------
<br>




# Labs

<table class="uk-table uk-table-striped">
<thead>
<tr>
   <th>DUE DATE</th>
   <th>TOPIC</th>
   <th>READING</th>
   <th>LAB</th>
   <th>DATA</th>
</tr>
</thead>
<tbody>
        <tr>
            <td>  Aug 24  </td>
            <td>  Markdown Documents </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/TEXTBOOK/docs/introduction-to-r.html"><b> CH1 </b></a>   </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/LABS/lab-01-instructions.html"><b>LAB 01</b></a>   </td>
            <td>  no data </td>
        </tr>
        <tr>
            <td>  Sept 2  </td>
            <td>  Functions and Vectors  </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/TEXTBOOK/docs/functions.html"><b> CH2 </b></a> 
                  <a href="https://ds4ps.github.io/Data-Science-Class/TEXTBOOK/docs/data-structures.html"><b> CH3 </b></a>
            </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/LABS/lab-02-instructions.html"><b>LAB 02</b></a>  </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/DATA/syr_parcels.html"><b>PARCELS</b></a>  </td>
        </tr>
        <tr>
            <td>  Sept 9  </td>
            <td>  Logical Operators  </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/TEXTBOOK/docs/logical-statements.html"><b> CH4 </b></a>   </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/LABS//lab-03-instructions.html"><b>LAB 03</b></a>  </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/DATA/syr_parcels.html"><b>PARCELS</b></a>   </td>
        </tr>
        <tr>
            <td>  Sept 16  </td>
            <td>  Descriptive Analysis  </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/TEXTBOOK/docs/the-dplyr-package.html"><b> CH5 </b></a>
                  <a href="https://ds4ps.github.io/Data-Science-Class/TEXTBOOK/docs/data-recipes.html"><b> CH7 </b></a>
                  <a href="https://ds4ps.github.io/Data-Science-Class/LECTURES/CH-05-data-verbs.html"><b> LECT5 </b></a>
                  <a href="https://ds4ps.github.io/Data-Science-Class/LECTURES/LECT-07-data-recipes.html"><b> LECT7 </b></a> </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/LABS//lab-04-instructions.html"><b>LAB 04</b></a> </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/DATA/syr_parcels.html"><b>PARCELS</b></a>  </td>
        </tr>    
        <tr>
            <td>  Sept 23  </td>
            <td>  Visualization I  </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/TEXTBOOK/docs/the-plot-function.html"><b> CH9 </b></a>
                  <a href="https://raw.githubusercontent.com/DS4PS/Data-Science-Class/master/HANDOUTS/regression_visual_example.R"><b> EXAMPLE </b></a>  </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/LABS//lab-05-instructions.html"><b> LAB 05 </b></a> </td>
            <td>  <a href="https://raw.githubusercontent.com/DS4PS/Data-Science-Class/master/DATA/CASchools.R"><b> Schools </b></a></td> 
        </tr> 
        <tr>  
            <td>  Sept 30  </td>
            <td>  Visualization II  </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/TEXTBOOK/docs/customizing-plots.html"><b> CH10 </b></a>   
                  <a href="https://ds4ps.github.io/Data-Science-Class/TEXTBOOK/docs/custom-plot-example.html"><b> CH11 </b></a></td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/LABS//lab-06-instructions.html"><b> LAB 06 </b></a> </td>
            <td>  <a href="https://cran.r-project.org/web/packages/Lahman/Lahman.pdf#Teams"><b> Lahman </b></a>  </td>
        </tr> 
        <tr> 
            <td>  Oct 5  </td> 
            <td>  Visualization III  </td>
            <td>  <a href="https://cdn.rawgit.com/DS4PS/Data-Science-Class/53c986f1/TEMPLATES/ShinyWidgetsDemo.Rmd"><b> DEMO  </b></a></td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/LABS//lab-07-instructions.html"><b> LAB 07 </b></a> </td>
            <td>  <a href="https://cran.r-project.org/web/packages/Lahman/Lahman.pdf#Teams"><b> Lahman </b></a>   </td>
        </tr> 
        <tr> 
            <td>  Oct 14  </td>
            <td>  Dashboards in R Markdown  </td>
            <td>  <a href="https://rmarkdown.rstudio.com/flexdashboard/layouts.html"><b> LAYOUTS  </b> 
                  </a> </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/LABS//lab-08-instructions.html"><b> LAB 08 </b></a></td>
            <td>  <a href="https://cran.r-project.org/web/packages/Lahman/Lahman.pdf#Teams"><b> Lahman </b></a>   </td>
        </tr> 
        <tr>  
            <td>  Oct 28  </td>
            <td>  Data IO (input, output)  </td>
            <td>  <a href="http://rpubs.com/JamisonCrawford/readingtextdata"><b> Tutorial  </b></a>  </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/LABS//lab-09-instructions.html"><b> LAB 09 </b></a> </td> 
            <td>  <a href="https://data.tempe.gov/dataset/high-severity-traffic-crashes-1-08"><b> CRASH DATA </b></a>  </td>
        </tr>
        <tr>
            <td>  Oct 28  </td>
            <td>  Joining Data  </td>
            <td>  None </td>
            <td>  <a href="https://ds4ps.github.io/Data-Science-Class/LABS//lab-10-instructions.html"><b> LAB 10 </b></a> </td>
            <td>  <a href="https://nccs-data.urban.org/dd2.php?close=1&form=Core+2010+PC"><b> NONPROFITS </b></a>  </td>
        </tr> 
        <tr>
            <td>  Nov 11  </td>
            <td>  Maps  </td>
            <td>   </td>
            <td>  LAB 11 </td>
            <td>  <a href="https://data.tempe.gov/dataset/high-severity-traffic-crashes-1-08"><b> CRASH DATA </b></a>   </td>
        </tr> 
        <tr>
            <td>  Nov 11  </td>
            <td>  Programming & Simulation  </td>
            <td>   </td>
            <td>  LAB 12 </td>
            <td>     </td>
        </tr> 
        <tr>
            <td>  Nov 18  </td>
            <td>  Dates & Text  </td>
            <td>   </td>
            <td>  Work on Final Project  </td>
            <td>  <a href="https://data.tempe.gov/dataset/high-severity-traffic-crashes-1-08"><b> CRASH DATA </b></a>  </td>
        </tr> 
        <tr>
            <td>  Nov 25  </td>
            <td>  Thanksgiving Week  </td>
            <td>    </td>
            <td>    </td>
            <td>    </td>
        </tr> 
        <tr>
            <td>  Dec 2  </td>
            <td>  No New Topic  </td>
            <td>    </td>
            <td>  Work on Final Project  </td>
            <td>    </td>
        </tr> 
        <tr>
            <td>  Fri. Dec 7  </td>
            <td>  FINAL PROJECT DUE  </td>
            <td>    </td>
            <td>  DASHBOARD  </td>
        </tr> 
</tbody>
</table>

<br>

Labs are worth 60% of your grade. They are graded pass-fail. You get to drop one lab.

You will submit labs via Canvas at <http://canvas.asu.edu>. 

<br>

-----------------
<br><br>





# Discussion Boards
  

Discussion boards are worth 20% of the final grade. We will be using Yellowdig, accessible from the link below:

**[YELLOWDIG BOARD](https://www.yellowdig.com/board/24436)**

Or on our Canvas site:

**[CANVAS PORTAL](http://www.canvas.asu.edu)**

Yellowdig is a Facebook-style discussion board that is organized different than traditional boards that are centered around threads on topics. Instead it has a feed where students create "pins" based upon the topic that week. You receive points for posting pins, for the resonses that you get to your ideas, for interacting on other students' pins, and when you receive accolades from students or the professor. In this way, it measures engagement rather than word counts used on traditional discussion board (if you post a bunch of long and boring blogs no one will respond to your pins).

The labs in the course focus on the technical skills of data science, so these discussions are meant to balance the class with an opportunity to explore some interesting topics and trends in technology and society. They are open-ended as a means to invite curiosity and critical thinkings.


### Topics:

DATES | TOPICS
------|---------
Aug 24-Sept 7 | Promise of Big Open Data 
Aug 31-Sept 7 | Perils of Big Open Data 
Sept 7-Sept 14 | Best of R Packages 
Sept 17-Sept 23 | Data Viz
Sept 24-Sept 30 | Bad Graphs 
Oct 1-Oct 7 | Graphing Packages in R
Oct 8-Oct 14 |  Your Professional Identity
Oct 15-Oct 21 | Data APIs
Oct 22-Oct 28 | Managing with Data  
Oct 29-Nov 4 | Moneyballing Government? 
Nov 5-Nov 11 | Open Innovation 
Nov 12-Nov 18 | Smart Cities 
Nov 19-Nov 25 | Social Media Tools 

<br>

----------------
<br>

### Aug 24-Sept 7: The Promise of Big, Open Data

The world is simultaneously generating more data than it has ever before, as well as pushing for policies for making government data more accessible and democratic. These trends and movements is an important enabling aspect of data science, becuse it provides opportunity for real insights that can change our understanding of systems and allow us to hold institutions accountable.

So ignoring potential problems with big and open data for now, read about two interesting cases where big and open data have offered deep insights into city planning and human nature. 

"[A Data Analyst's Blog](https://www.npr.org/sections/alltechconsidered/2014/11/28/367046864/a-data-analysts-blog-is-transforming-how-new-yorkers-see-their-city
) Is Transforming How New Yorkers See Their City", NPR, Nov 2018.

[How a blog saved OK Cupid](https://fivethirtyeight.com/features/christian-rudder-dataclysm-okcupid/), FiveThirtyEight Blog, Nov 2014.


<br> 

**ASSIGNMENT:** 
> For your discussion topic this week, find one data-driven blog post from Ben Wellington's [I Quant NY](http://iquantny.tumblr.com/) and/or OK Cupid's [OK Trends](https://theblog.okcupid.com/tagged/data) where you discovered something cool that you did not know, and share it with the group. In your post highlight what is interesting about the example, and what data made it possible.

<br>

You can also check out Ben's [Ted Talk](https://www.youtube.com/watch?v=6xsvGYIxJok), or this short interview. 

<iframe width="560" height="315" src="https://www.youtube.com/embed/ZTdPpoUp25w?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

<br>

-----------------
<br>


### Aug 31-Sept 7: The Perils of Open Data

Big and open data can generate powerful insights, but with great power comes great responsibility. In some cases, it might create transparency and improve policy. In others it can be used to manipulate populations and distort accountability. 

"[The Data that Turned the World Upside Down:](https://publicpolicy.stanford.edu/news/data-turned-world-upside-down) How Cambridge Analytica used your Facebook data to help the Donald Trump campaign in the 2016 election.", 

This example poses many interesting dilemas. The Obama campaign was celebrated for using data to enhance voter mobilization. One can argue that the Trump campaign simply embraced the same strategy. Are we being unfair to laude one candidate for his data acumen but criticize another for similar tactics? What are the important differences between the two cases? 

**ASSIGNMENT:**  
> For your disccusion this week, post a pin with some thoughts about the potential downside of big & open data, ethics in a time of big data, and what sorts of privacy rules you would devise to balance the benefits that can come from access to data along with challenges of data governance.

<br>

-----------------
<br>


### Sept 9 - Sept 16: The Best of R

You might not have heard, but [nerd is the new black](https://www.wsj.com/articles/SB10001424127887323478304578332850293360468), data science is the [sexiest job of the 21st century](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century), and there is [nothing hotter](http://www.startfactor.pt/uploads/3/8/5/0/38505347/r-is-still-hot.pdf) than learning R.

But what is R, and what are the ~~nerds~~ cool kids using it for? 

**This week, your task is to explore a few blogs about tools in R and find one package or application that you are excited about. It can be an analytics package, a graphics package, a specific application, or otherwise.**

Mine, personally, was the package that allows you to create comic strip graphics in R:

[xkcd comics](https://stackoverflow.com/questions/12675147/how-can-we-make-xkcd-style-graphs)

Be warned up-front, this assignment might be overwhelming in you are wading into a new community where the technical language is unfamiliar and the volume of information vast. There are currently over 13,000 packages available in R! That is partly the point of the assignment - recognizing the sheer volume of creativity surrounding the R community. But also learning how to find some sources that make the content accessible. Here are a few to get you started:

[awesome r](https://awesome-r.com/)

[cran views](https://cran.r-project.org/web/views/)

[best of r blogs](https://blog.feedspot.com/r_programming_blogs/)

[r-bloggers](https://www.r-bloggers.com/)



<br>

-----------------
<br>


### Sept 17 - Sept 23: Data Visualization

To kick-off our data visualization segment of the course, this exercise is designed to introduce you to some cool data visualizaion communities. 

[Makeover Mondays](http://www.makeovermonday.co.uk/) is a weekly exercise where an organization shares a mediocre visualization and the data used to create it, then volunteers from around the world work to create a more informative or compelling visualization.

For your post this week, please select one graphic from their [Gallery](http://www.makeovermonday.co.uk/gallery/), post it to YellowDig, and explain what you think makes the graphic compelling? What works? **Specific, how did the creators use graphical or design elements to generate insight from the data, create a story, and leave the viewer with a clear take-away?**


<br>

-----------------
<br>



### Sept 24 - Sept 30: Bad Graphs

There is a lot of science behind data visualization, but the art to storytelling with data can be hard to distill into a few basic principles. As a result, it takes time to learn how to do it well. The best way to develop data visualization skill is to regularly consume interesting graphics. David McCandless is one of the best ambassadors for the field of graphic design and visualization. Check out his TED Talk,  and some excerpts from his book [*Information is Beautiful*]( https://github.com/DS4PS/Data-Science-Class/raw/master/READINGS/mccandless_information_is_beautiful.pdf).

<div style="max-width:560px"><div style="position:relative;height:0;padding-bottom:56.25%"><iframe src="https://embed.ted.com/talks/david_mccandless_the_beauty_of_data_visualization" width="854" height="480" style="position:absolute;left:0;top:0;width:100%;height:100%" frameborder="0" scrolling="no" allowfullscreen></iframe></div></div>

Unfortunatly, it is much easier to create tragically bad graphics than it is to create good graphics. For your blog this week, read the *Calling Bullshit* overview on [proportional ink](https://callingbullshit.org/tools/tools_proportional_ink.html) and [misleading axes](https://callingbullshit.org/tools/tools_misleading_axes.html) to develop some sensitivity about misleading graphics. 

Find a graph that violates one of these principles, or commits an equally egregious visualization crime. Share the graph and explain what offense has been committed. You might start by searching for "bad graphs" on google. 

This use of [clowns](https://peltiertech.com/bad-bar-chart-practices-or-send-in-the-clowns/) in bar charts is one of my favorites. You might also enjoy [pizza charts](http://getdolphins.com/blog/the-worst-graphs-of-2017/) or [these gems](https://www.distractify.com/humor/2017/05/26/cszBB/hilariously-bad-graphs). 


<br>

-----------------
<br>



### Oct 1 - Oct 7:  R Graphics Packages

For labs thus far we have used the core R graphics engine, but we have not utilized some of the many useful [graphics packages](https://cran.r-project.org/web/views/Graphics.html) in R. This discussion topic offers an opportunity to explore some options.

Your task is to select a specialized graphic that you could use in your own research or professional life, then describe what data or topic from your own work the visualization would be useful for. Reference what R package you would need for the task.

For example, I might say that I work creating budgets for a government organization. I could use a [Sankey Diagram](https://www.getrichslowly.org/sankey-diagrams/) from the [D3 Package](https://www.r-graph-gallery.com/sankey-diagram/) to visualize our budget. 

You will find sites like the [R Graphs Gallery](https://www.r-graph-gallery.com/) and [The Data Viz Project](https://datavizproject.com/) helpful.


<br>

-----------------
<br>



### Oct 8 - Oct 14:  Do you Data Science? 

Planet Money had a [fascinating podcast](https://www.npr.org/sections/money/2016/07/22/487069271/episode-576-when-women-stopped-coding) about the rise and fall of women in computer science (you can see a short written synopse [here](https://www.npr.org/sections/money/2014/10/21/357629765/when-women-stopped-coding)). 

<img src="https://raw.githubusercontent.com/DS4PS/course_website/master/assets/img/women_in_cs.png" 
alt="women in cs" width="700" />

The part of the story I found most fascinating was the schools that were able to turn the trend around using a few simple rules, and create computer science programs that were 50% women. Start at [minute 13:00](https://www.npr.org/sections/money/2016/07/22/487069271/episode-576-when-women-stopped-coding) to learn how.

Most of you are social science or humanities students without a lot of background in computer programming. What has your experience been in this course? Would you have taken the class if it had been called "computer science" instead of "data science"? In the podcast women were marginalized in the field of computer science. The modern version of this story is public sector workers and nonprofit managers that are constantly told that they are not good with data, that they should rely on outside "experts" for this work. Based on your experiences this semester, how can we overcome these stereotypes to make government and social sectors more data-driven and more effective? 


<br>

-----------------
<br>




### Oct 15 - Oct 21:  Useful Data APIs

Part of the reason data science has grown so much as a field in recent years is because of advances in computing technologies that allows us to run powerful programs and to work with large datasets on our own machines. But another important reason is that data has become so ubiquitous and cheap, but paradoxically also more valuable for organizations. 

Your skill level in data science can be measured by how quickly you can take a real-world problem and produce analysis that offers better solutions than the status quo. Analyzing the data is important, but the process of obtaining data is not a trivial step. Having knowledge about where to look for data, or how to augment your existing data, will help you be more effective as an analyst. 

This section in the course focuses on finding data and getting it into R. You can always download datasets from standard sites like the US Census, then import whatever file type is provided into R using import functions. Alternatively, you can use an API.

API stands for "Application Programming Interface", which is computer science jargon for the protocols used when two applications speak to each other. If you are using your mobile phone and you want to log into your bank using an app, an API will allow you to send your user credential and password to your bank, and will return information about your balances and transactions. APIs are just structured ways of sending data back and fourth. They create templates that allow the user to ask a question or a "query" (e.g. what is my checking account balance?), and the application to send an answer.

In some cases, organizations that host public datasets have created data APIs. In these instances the user asks for a specific dataset, and the app sends a file as a response. To see some examples of how this works, visit the [Data Science Toolkit](http://www.datasciencetoolkit.org), and test out the examples to see what sorts of data you might access through APIs. In some cases you give some search parameters (such as a zip code), and it returns a new dataset (census data). In other cases, you send data (raw text), and the API sends you a processed version of the data (a sentiment score based upon words in the text). Thus APIs are used both to access new data sources, as well as to clean or process your current data as part of your project.

The good news is that the R community has made a lot of APIs easier to use by creating packages that allow you to use R functions to access data. For example, there is a Facebook package and a Twitter package that allow you to download social media data by sending a request for specific dates and specific users. The R package will provide a function with some arguments for you, which will then translate your request into the correct API format, send the request, then return that data directly to R as a data frame or list. In this way, you can quickly access thousands of datasets in real time through R.

For your post this week, do a Google search and find an example of an API that you might find useful for your work. For example, I use a lot of federal data, so I have found this site to be a useful source of data I did not know existed:

https://theunitedstates.io/APIs/

Altnernatively, you can report on an interesting package in R that uses a data API. Note, you do not have to use the API for the post, just identify what information is accessible through the system. 



<br>

-----------------
<br>




### Oct 22 - Oct 29:  Managing with Data

Ever since Michael Lewis popularized the story of the Oakland A's using data-driven management to overcome huge budget disparities to achieve the underdog story of the decade, every industry is trying to figure out how to "moneyball" performance - i.e. substituting good data for the normal inputs into high-performing organizations like human capital, financial capital, or culture:

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/TpBcwGOvO80?controls=0" frameborder="0" allowfullscreen></iframe>

<br><br>

Data-driven management can be a double-edged sword, though. Fans of the hit TV show The Wire will recognize the dramatic portrayal of Baltimore's CityStat system:

<iframe width="560" height="315" src="https://www.youtube.com/embed/xH_6_8NOfwI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

As governments and nonprofits begin embracing the use of data to actively inform decision-making, the management practices sometimes need to catch up with the data. The new book [The Goldilocks Challenge](https://ssir.org/articles/entry/ten_reasons_not_to_measure_impact_and_what_to_do_instead) cautions against jumping right into impact measurement, and instead focusing on management fundamentals first. 

Is your current organizations (or one you have recently worked with) collecting data for strategic management purposes? Does it have the proper management practices in place to fully utilize that data that is collected, or is the current data not used to its full potential? If you had to suggest one new data-driven management practice, what would it be?  

<br>
-----------------
<br>

# Course Overview

Welcome to Intro to Data Science for the Social Sector. This is a broad overview course designed to expose you to common and useful open source tools in the field. 

A few notes about the semester:


### Rules for Success

Learning a new skill like R programming is never painless, but you can follow a few simple rules to succeed at this course:

* Find a study group.
* Work until you get stuck, then post a question to the [discussion forum](https://ds4ps.github.io/course_website/discussions/).
* [Schedule office hours](https://calendly.com/lecy/15min) when needed.
* Attend weekly review sessions
 

### Data Science Applications in the Social Sector

It is always helpful to motivate a topic with an example. I like this case study of change that occurred when the Philadelphia police began transitioning from managing a department using instinct of senior officers to using data to identify areas of high need and most effective practices.

<iframe width="560" height="315" src="https://www.youtube.com/embed/ZJNESMhIxQ0?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>


### What is Data Science? 

"A data scientist is a person who should be able to leverage existing data sources, and create new ones as needed in order to extract meaningful information and actionable insights. These insights can be used to drive business decisions and changes intended to achieve business goals... ‘The Perfect Data Scientist’ is the individual who is equally strong in business, programming, statistics, and communication."

FROM: [ What Is Data Science, and What Does a Data Scientist Do? ](https://www.innoarchitech.com/what-is-data-science-does-data-scientist-do/)

"Universities can hardly turn out data scientists fast enough. To meet demand from employers, the United States will need to increase the number of graduates with skills handling large amounts of data by as much as 60 percent."

FROM: [Data Science: The Numbers of Our Lives, The New York Times](https://www.nytimes.com/2013/04/14/education/edlife/universities-offer-courses-in-a-hot-new-field-data-science.html)

“Data Scientists identify complex business problems whilst leveraging data value. They work as part of a multidisciplinary team with data architects, data engineers, analysts and others.”

FROM: [Data Scientist Career Pathways in Government](https://github.com/ukgovdatascience/data_scientist_career_path/blob/master/index.md).


### Why R?

This course is organized around learning the foundations of programming in R. Although there are several good choices for languages that specialize in data analysis, R has advantages:

* It is completely free and open source.
* It has a large and active user community.
* R Studio has integrated many tools from the 'data science ecosystem' so that lots of tasks can be done with a single language, making the return on time spent learning R much higher.

For some background information on R, read the New York Times story: [Data Analysts Captivated by R’s Power](https://www.nytimes.com/2009/01/07/technology/business-computing/07program.html). Or Check out this 1-minute explainer video:

<br>

<iframe src="https://player.vimeo.com/video/180644880" width="640" height="360" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>

<br>

You will find this background information helpful as you start using R:

* [ Helpful Vocabulary ](https://github.com/DS4PS/Data-Science-Class/raw/master/HANDOUTS/Helpful%20Programming%20Vocabulary.pdf)
* [ Base R Cheat Sheet ](https://www.rstudio.com/wp-content/uploads/2016/05/base-r.pdf)

See the [Resources](https://ds4ps.github.io/course_website/resources/) tab for some additional information about R and R Studio.


<br>

-----------------
<br>





# Class Roster

Meet your classmates:

[ Roster for Data Science for the Public Sector, Fall 2018 ](https://ds4ps.github.io/Data-Science-Class/MISC/bios_lab_01/ROSTER.html)

<br>

<br><br><br><br>
</div>
